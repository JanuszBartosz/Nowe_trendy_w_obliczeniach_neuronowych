{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x7fb7e843d470> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb767676748> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb767676550> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fb767676828> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb767628898> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb767628eb8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fb76764e208> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb7673ca320> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb7673d9dd8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb7673fde10> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fb767390780> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb7673a2588> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb767348d68> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb769521358> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fb76736b5f8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb7673205c0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb767320e48> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb7672c62b0> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fb7672d8828> True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from math import floor, ceil\n",
    "\n",
    "import numpy\n",
    "from keras import layers, metrics\n",
    "from keras import models, optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications import VGG16\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import *\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train_dir = '/home/snowflake/Documents/nowe_trendy/train'\n",
    "test_dir = '/home/snowflake/Documents/nowe_trendy/test'\n",
    "validation_dir = '/home/snowflake/Documents/nowe_trendy/validation'\n",
    "\n",
    "path, dirs, files = os.walk(train_dir).__next__()\n",
    "\n",
    "val_size = 0.15\n",
    "nTrain = sum([len(files) for r, d, files in os.walk(train_dir)]) - len(dirs)\n",
    "nVal = ceil(nTrain * val_size)\n",
    "path, dirs, files = os.walk(test_dir).__next__()\n",
    "nTest = sum([len(files) for r, d, files in os.walk(test_dir)]) - len(dirs)\n",
    "nClasses = len(dirs)\n",
    "batch_size = 20\n",
    "dense_size = 256\n",
    "epochs = 10\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in conv_base.layers:\n",
    "    print(layer, layer.trainable)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(dense_size, activation='relu', input_dim=7 * 7 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "train_batchsize = 12\n",
    "val_batchsize = 8\n",
    "dense_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7875 images belonging to 12 classes.\n",
      "Found 1818 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode=\"nearest\",\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Configure model for training************\n"
     ]
    }
   ],
   "source": [
    "print(\"**********Configure model for training************\")\n",
    "\n",
    "mcp_save = ModelCheckpoint('best_model_acc.model', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
    "model.compile(optimizer=optimizers.Adamax(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Start of training************\n",
      "Epoch 1/20\n",
      "657/656 [==============================] - 2414s 4s/step - loss: 2.4549 - categorical_accuracy: 0.1433 - val_loss: 2.4515 - val_categorical_accuracy: 0.1315\n",
      "Epoch 2/20\n",
      "657/656 [==============================] - 2591s 4s/step - loss: 2.4206 - categorical_accuracy: 0.1487 - val_loss: 2.4539 - val_categorical_accuracy: 0.1315\n",
      "Epoch 3/20\n",
      "657/656 [==============================] - 2590s 4s/step - loss: 2.4216 - categorical_accuracy: 0.1483 - val_loss: 2.4520 - val_categorical_accuracy: 0.1315\n",
      "Epoch 4/20\n",
      "657/656 [==============================] - 2594s 4s/step - loss: 2.4198 - categorical_accuracy: 0.1488 - val_loss: 2.4556 - val_categorical_accuracy: 0.1315\n",
      "Epoch 5/20\n",
      "657/656 [==============================] - 2651s 4s/step - loss: 2.4201 - categorical_accuracy: 0.1485 - val_loss: 2.4540 - val_categorical_accuracy: 0.1315\n",
      "Epoch 6/20\n",
      "657/656 [==============================] - 2575s 4s/step - loss: 2.4203 - categorical_accuracy: 0.1489 - val_loss: 2.4532 - val_categorical_accuracy: 0.1315\n",
      "Epoch 7/20\n",
      "657/656 [==============================] - 2619s 4s/step - loss: 2.4204 - categorical_accuracy: 0.1481 - val_loss: 2.4533 - val_categorical_accuracy: 0.1315\n",
      "Epoch 8/20\n",
      "657/656 [==============================] - 2648s 4s/step - loss: 2.4198 - categorical_accuracy: 0.1485 - val_loss: 2.4518 - val_categorical_accuracy: 0.1315\n",
      "Epoch 9/20\n",
      "657/656 [==============================] - 2633s 4s/step - loss: 2.4202 - categorical_accuracy: 0.1485 - val_loss: 2.4535 - val_categorical_accuracy: 0.1315\n",
      "Epoch 10/20\n",
      "657/656 [==============================] - 2620s 4s/step - loss: 2.4205 - categorical_accuracy: 0.1481 - val_loss: 2.4531 - val_categorical_accuracy: 0.1315\n",
      "Epoch 11/20\n",
      "496/656 [=====================>........] - ETA: 8:42 - loss: 2.4202 - categorical_accuracy: 0.1482"
     ]
    }
   ],
   "source": [
    "print(\"**********Start of training************\")\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "                    callbacks = [mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('last_model_acc.model')\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model_acc.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator for prediction\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_dir = '/home/snowflake/Documents/nowe_trendy/test'\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    " \n",
    "# Get the filenames from the generator\n",
    "fnames = test_generator.filenames\n",
    " \n",
    "# Get the ground truth from generator\n",
    "ground_truth = test_generator.classes\n",
    " \n",
    "# Get the label to class mapping from the generator\n",
    "label2index = test_generator.class_indices\n",
    " \n",
    "# Getting the mapping from class index to class label\n",
    "idx2label = dict((v,k) for k,v in label2index.items())\n",
    " \n",
    "# Get the predictions from the model using the generator\n",
    "predictions = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size,verbose=1)\n",
    "predicted_classes = np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.where(predicted_classes.round() != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))\n",
    "accuracy = accuracy_score(ground_truth, predicted_classes)\n",
    "print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"**********End of training************\\n\\n\")\n",
    "\n",
    "# ground_truth = [np.where(r == 1)[0][0] for r in test_labels]\n",
    "\n",
    "# predictions = model.predict_classes(test_features)\n",
    "# prob = model.predict(test_features)\n",
    "\n",
    "# # errors = nVal - accuracy_score(ground_truth, predictions, normalize=False)\n",
    "# errors = np.where(predictions != ground_truth)[0]\n",
    "# accuracy = accuracy_score(ground_truth, predictions)\n",
    "# precision, recall, f_score, support = score(ground_truth, predictions, average='weighted')\n",
    "\n",
    "# print(\"No of errors = {}/{}\".format(len(errors), nTest))\n",
    "# print(\"Accuracy: {}\".format(accuracy))\n",
    "# print(\"Weighted average Precision: {}\".format(precision))\n",
    "# print(\"Weighted average Recall: {}\".format(recall))\n",
    "# print(\"Weighted average F-score: {}\".format(f_score))\n",
    "\n",
    "# end = time.time()\n",
    "# print(\"Time: \" + str(end - start))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "618px",
    "left": "1172px",
    "right": "20px",
    "top": "72px",
    "width": "490px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
